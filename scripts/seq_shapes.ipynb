{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a fake sequence of 10 images, the shape that comes out from DALI\n",
    "seq_len = 10\n",
    "img_shape = (3, 2, 2)\n",
    "img_seq = torch.zeros((seq_len,) + img_shape)\n",
    "for i in range(seq_len):\n",
    "    img = torch.ones(img_shape) * i\n",
    "    img_seq[i] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_seq.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our goal is to extract 5-frame sequences from this sequence\n",
    "net_seq_len = 5\n",
    "train_seq = torch.zeros((seq_len, net_seq_len, *img_shape), device=img_seq.device)\n",
    "# define pads: start pad repeats the zeroth image twice. end pad repeats the last image twice.\n",
    "# this is to give padding for the first and last frames of the sequence\n",
    "pad_start = torch.tile(img_seq[0].unsqueeze(0), (2, 1,1,1))\n",
    "pad_end = torch.tile(img_seq[-1].unsqueeze(0), (2, 1,1,1))\n",
    "# pad the sequence\n",
    "padded_seq = torch.cat((pad_start, img_seq, pad_end), dim=0)\n",
    "#padded_seq = torch.cat((two_pad, img_seq, two_pad), dim=0)\n",
    "for i in range(seq_len):\n",
    "    # extract 5-frame sequences from the padded sequence\n",
    "    train_seq[i] = padded_seq[i:i+net_seq_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final image assertion\n",
    "assert(torch.allclose(train_seq[-1][-1], img_seq[-1]))\n",
    "assert(torch.allclose(train_seq[-1][-3], img_seq[-1]))\n",
    "assert(~torch.allclose(train_seq[-1][-5], img_seq[-1]))\n",
    "\n",
    "# image 0 assertion\n",
    "assert(torch.allclose(train_seq[0][0], img_seq[0]))\n",
    "assert(torch.allclose(train_seq[0][2], img_seq[0]))\n",
    "assert(torch.allclose(train_seq[0][4], img_seq[2]))\n",
    "\n",
    "# middle image assertion\n",
    "assert(torch.allclose(train_seq[5][0], img_seq[3]))\n",
    "assert(torch.allclose(train_seq[5][1], img_seq[4]))\n",
    "assert(torch.allclose(train_seq[5][2], img_seq[5]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_seq[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_pad = torch.zeros(2, *img_shape)\n",
    "two_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 3, 2, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq = torch.cat((two_pad, img_seq, two_pad), dim=0)\n",
    "padded_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6964ab66c8ce41bab5abbdc85388b1f8a48a840390c4bfc468bfa8058a9a7c96"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('pose-estimation-nets')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
